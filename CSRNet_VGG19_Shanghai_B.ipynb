{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8512969,
          "sourceType": "datasetVersion",
          "datasetId": 5082019
        },
        {
          "sourceId": 8512975,
          "sourceType": "datasetVersion",
          "datasetId": 5082024
        },
        {
          "sourceId": 8512980,
          "sourceType": "datasetVersion",
          "datasetId": 5082028
        },
        {
          "sourceId": 8513066,
          "sourceType": "datasetVersion",
          "datasetId": 5082099
        },
        {
          "sourceId": 8513079,
          "sourceType": "datasetVersion",
          "datasetId": 5082108
        },
        {
          "sourceId": 8584613,
          "sourceType": "datasetVersion",
          "datasetId": 5134316
        },
        {
          "sourceId": 8553377,
          "sourceType": "datasetVersion",
          "datasetId": 5111452
        },
        {
          "sourceId": 8553421,
          "sourceType": "datasetVersion",
          "datasetId": 5111483
        }
      ],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.cm as cm\n",
        "import time\n",
        "import skimage.measure\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.models import model_from_json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg19 import preprocess_input"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-07-15T22:07:13.430370Z",
          "iopub.execute_input": "2024-07-15T22:07:13.430994Z",
          "iopub.status.idle": "2024-07-15T22:07:27.112165Z",
          "shell.execute_reply.started": "2024-07-15T22:07:13.430957Z",
          "shell.execute_reply": "2024-07-15T22:07:27.111106Z"
        },
        "trusted": true,
        "id": "Zg_v6LotmFYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save into array Train images, Ground Truth and Labels"
      ],
      "metadata": {
        "id": "bvLmmTCimFYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_imgs_B = []\n",
        "Train_density_B = []\n",
        "Train_labels_B = []\n",
        "\n",
        "path_images = \".../train_data/images/\"\n",
        "path_heads = \".../train_data/ground_truth/\"\n",
        "path_maps = \".../train_data/maps/\"\n",
        "\n",
        "\n",
        "\n",
        "for img_name, den_name, heads_name in zip(sorted(os.listdir(path = path_images)), sorted(os.listdir(path = path_maps)), sorted(os.listdir(path = path_heads))):\n",
        "\n",
        "    img = preprocess_input(cv2.cvtColor(cv2.imread(path_images + img_name), cv2.COLOR_BGR2RGB))\n",
        "    Train_imgs_B.append(img)\n",
        "\n",
        "    img = np.load(path_maps + den_name)\n",
        "    Train_density_B.append(img)\n",
        "\n",
        "    Train_labels_B.append(len(loadmat(path_heads + heads_name)['image_info'][0, 0][0, 0][0]))\n",
        "\n",
        "\n",
        "Train_imgs_B = np.asarray(Train_imgs_B)\n",
        "Train_density_B = np.asarray(Train_density_B)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-15T22:07:27.114033Z",
          "iopub.execute_input": "2024-07-15T22:07:27.114563Z",
          "iopub.status.idle": "2024-07-15T22:07:40.875644Z",
          "shell.execute_reply.started": "2024-07-15T22:07:27.114538Z",
          "shell.execute_reply": "2024-07-15T22:07:40.874596Z"
        },
        "trusted": true,
        "id": "VnlE0JWqmFYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save into array Test images, Ground Truth and Labels"
      ],
      "metadata": {
        "id": "mfR7bVVUmFYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Test_imgs_B = []\n",
        "Test_density_B = []\n",
        "Test_labels_B = []\n",
        "\n",
        "path_images = \".../test_data/images/\"\n",
        "path_heads = \".../test_data/ground_truth/\"\n",
        "path_maps = \".../test_data/maps/\"\n",
        "\n",
        "\n",
        "for img_name, den_name, heads_name in zip(sorted(os.listdir(path = path_images)), sorted(os.listdir(path = path_maps)), sorted(os.listdir(path = path_heads))):\n",
        "\n",
        "    Test_imgs_B.append(preprocess_input(cv2.cvtColor(cv2.imread(path_images + img_name), cv2.COLOR_BGR2RGB)))\n",
        "    Test_density_B.append(np.load(path_maps + den_name))\n",
        "    Test_labels_B.append(len(loadmat(path_heads + heads_name)['image_info'][0, 0][0, 0][0]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-15T22:07:40.877015Z",
          "iopub.execute_input": "2024-07-15T22:07:40.877315Z",
          "iopub.status.idle": "2024-07-15T22:07:48.633431Z",
          "shell.execute_reply.started": "2024-07-15T22:07:40.877290Z",
          "shell.execute_reply": "2024-07-15T22:07:48.632565Z"
        },
        "trusted": true,
        "id": "3RbGGkjtmFYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "K51Gejh4mFYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Conv2D, LeakyReLU, Input\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "weights_path = \".../vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "#adam = Adam(learning_rate=1e-7)\n",
        "\n",
        "def build_CSRnet(input_shape):\n",
        "    VGG_19 = VGG19(weights=weights_path, include_top=False, input_shape=input_shape)\n",
        "\n",
        "\n",
        "    VGG_19 = Model(inputs=VGG_19.input, outputs=VGG_19.get_layer('block4_conv4').output)\n",
        "\n",
        "    Map_estimator_net = Sequential([\n",
        "        Conv2D(512, (3, 3), dilation_rate=2, padding='same', kernel_initializer=RandomNormal(stddev=0.01)),\n",
        "        LeakyReLU(negative_slope=0.01),\n",
        "        Conv2D(512, (3, 3), dilation_rate=2, padding='same', kernel_initializer=RandomNormal(stddev=0.01)),\n",
        "        LeakyReLU(negative_slope=0.01),\n",
        "        Conv2D(512, (3, 3), dilation_rate=2, padding='same', kernel_initializer=RandomNormal(stddev=0.01)),\n",
        "        LeakyReLU(negative_slope=0.01),\n",
        "        Conv2D(256, (3, 3), dilation_rate=2, padding='same', kernel_initializer=RandomNormal(stddev=0.01)),\n",
        "        LeakyReLU(negative_slope=0.01),\n",
        "        Conv2D(128, (3, 3), dilation_rate=2, padding='same', kernel_initializer=RandomNormal(stddev=0.01)),\n",
        "        LeakyReLU(negative_slope=0.01),\n",
        "        Conv2D(64, (3, 3), dilation_rate=2, padding='same', kernel_initializer=RandomNormal(stddev=0.01)),\n",
        "        LeakyReLU(negative_slope=0.01),\n",
        "        Conv2D(1, (1, 1), dilation_rate=1, padding='same', kernel_initializer=RandomNormal(stddev=0.01)),\n",
        "        LeakyReLU(negative_slope=0.01)\n",
        "    ])(VGG_19.output)\n",
        "\n",
        "    CSRnet = Model(inputs=VGG_19.input, outputs=Map_estimator_net)\n",
        "    CSRnet.compile(optimizer=SGD(learning_rate=1e-2, decay=5e-4, momentum=0.9), loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "    return CSRnet\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-15T22:09:37.931206Z",
          "iopub.execute_input": "2024-07-15T22:09:37.931852Z",
          "iopub.status.idle": "2024-07-15T22:09:37.950532Z",
          "shell.execute_reply.started": "2024-07-15T22:09:37.931820Z",
          "shell.execute_reply": "2024-07-15T22:09:37.949537Z"
        },
        "trusted": true,
        "id": "dJ-xl_NqmFYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test functions definition"
      ],
      "metadata": {
        "id": "nJ5Cxa4vmFYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def train_CSRnet(CSRnet, Train_imgs_B, Train_density_B, checkpoint_filepath):\n",
        "    if not os.path.exists('./checkpoints'):\n",
        "        os.makedirs('./checkpoints')\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_mae',\n",
        "        mode='min',\n",
        "        save_best_only=True,\n",
        "        verbose=1)\n",
        "\n",
        "    early_stopping_callback = EarlyStopping(\n",
        "        monitor='val_mae',\n",
        "        patience=15,\n",
        "        mode='min',\n",
        "        verbose=1,\n",
        "        restore_best_weights=True)\n",
        "\n",
        "    history = CSRnet.fit(Train_imgs_B, Train_density_B,\n",
        "                         batch_size=1, epochs=100,\n",
        "                         validation_split=0.1, steps_per_epoch=100,\n",
        "                         callbacks=[model_checkpoint_callback])\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "def test_CSRnet(CSRnet, Test_imgs, Test_labels, file_parameters_path):\n",
        "    CSRnet.load_weights(file_parameters_path)\n",
        "\n",
        "    mae_error = 0\n",
        "    mse_error = 0\n",
        "    mape_error = 0\n",
        "\n",
        "\n",
        "    N = len(Test_labels)\n",
        "    for i, (x, y) in enumerate(zip(Test_imgs, Test_labels)):\n",
        "\n",
        "        print(i)\n",
        "\n",
        "        mae_error += np.abs(np.sum(CSRnet.predict(np.reshape(np.asarray(x),(1, x.shape[0], x.shape[1], x.shape[2])))) - y)\n",
        "        mse_error += np.square(np.sum(CSRnet.predict(np.reshape(np.asarray(x),(1, x.shape[0], x.shape[1], x.shape[2])))) - y)\n",
        "        mape_error += np.abs((np.sum(CSRnet.predict(np.reshape(np.asarray(x),(1, x.shape[0], x.shape[1], x.shape[2])))) - y) / y)* 100\n",
        "\n",
        "    return mae_error/N, mse_error/N, mape_error/N\n",
        "\n",
        "checkpoint_filepath = './checkpoints/checkpoint.weights.h5'\n",
        "\n",
        "input_shape = (None, None, 3)\n",
        "\n",
        "CSRnet = build_CSRnet(input_shape)\n",
        "CSRnet.summary()\n",
        "\n",
        "\n",
        "history = train_CSRnet(CSRnet, Train_imgs_B, Train_density_B, checkpoint_filepath)\n",
        "\n",
        "if os.path.isfile(checkpoint_filepath):\n",
        "    print(f\"The best weights have been saved in: {checkpoint_filepath}\")\n",
        "else:\n",
        "    print(f\"The weights were not saved correctly. Check the path: {checkpoint_filepath}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-15T22:09:46.167637Z",
          "iopub.execute_input": "2024-07-15T22:09:46.168446Z"
        },
        "trusted": true,
        "id": "25P1k8PimFYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test values"
      ],
      "metadata": {
        "id": "vmwqq0lbmFYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae, mse, mape  = test_CSRnet(CSRnet, Test_imgs_B, Test_labels_B, checkpoint_filepath)\n",
        "print(f\"Mean Absolute Error: {mae}, Mean Square Error: {mse}, Mean Absolute Percentage Error:{mape}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ofA5owFFmFYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print some images and train curve"
      ],
      "metadata": {
        "id": "nyeHIP-HmFYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_print = 15\n",
        "plt.figure(figsize=(9, 3 * to_print))\n",
        "path_images = \".../test_data/images/\"\n",
        "path_heads = \".../test_data/ground_truth/\"\n",
        "\n",
        "for i, (img, dens, raw, head) in enumerate(zip(Test_imgs_B, Test_density_B, sorted(os.listdir(path = path_images)),sorted(os.listdir(path = path_heads)))):\n",
        "    if i == to_print: break\n",
        "\n",
        "    estimated_dens = CSRnet.predict(np.reshape(np.asarray(img),(1,img.shape[0],img.shape[1],img.shape[2])))\n",
        "\n",
        "    heads = loadmat(path_heads + head)\n",
        "    true_number=len(heads['image_info'][0, 0][0, 0][0])\n",
        "    predicted_number=int(np.sum(estimated_dens))\n",
        "\n",
        "    plt.subplot(to_print, 3, i * 3 + 1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Test image:\")\n",
        "    plt.imshow(cv2.cvtColor(cv2.imread(path_images + raw), cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    plt.subplot(to_print, 3, i * 3 + 2)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"GT density map:\")\n",
        "    plt.title(f\"GT density map\\nGT count: {true_number:.2f}\")\n",
        "\n",
        "    plt.imshow(dens , cmap = cm.jet)\n",
        "\n",
        "\n",
        "    plt.subplot(to_print, 3, i * 3 + 3)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Estimated density map:\")\n",
        "    plt.title(f\"Estimated density map\\nEstimated count: { predicted_number:.2f}\")\n",
        "\n",
        "    plt.imshow(estimated_dens.reshape((estimated_dens.shape[1], estimated_dens.shape[2], 1)) , cmap = cm.jet)"
      ],
      "metadata": {
        "trusted": true,
        "id": "vLYF0BJhmFYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves(history):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(history.epoch,history.history['loss'], label='train loss')\n",
        "    plt.plot(history.epoch,history.history['val_loss'], label='valid loss')\n",
        "    plt.legend()\n",
        "    plt.title('loss')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "plot_learning_curves(history)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "B3hrpKIomFYs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}